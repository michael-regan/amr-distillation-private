{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8da9dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/Users/office/Documents/portfolio\")\n",
    "import sembleu\n",
    "import os, json, math, random, time\n",
    "\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "\n",
    "from sembleu import src\n",
    "from sembleu.src import bleu_score\n",
    "from sembleu.src.bleu_score import corpus_bleu, sentence_bleu, SmoothingFunction, NgramInst\n",
    "\n",
    "from sembleu.src import amr_graph\n",
    "from sembleu.src.amr_graph import AMRGraph\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import fractions\n",
    "try:\n",
    "    fractions.Fraction(0, 1000, _normalize=False)\n",
    "    from fractions import Fraction\n",
    "except TypeError:\n",
    "    from nltk.compat import Fraction\n",
    "\n",
    "from collections import namedtuple\n",
    "NgramInst = namedtuple('NgramInst', 'ngram length')\n",
    "\n",
    "#from transformers import LlamaTokenizer\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d3b72c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_ = Path('/Users/office/Documents/AMRs-2022/massive-qa-amrs/data/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "825baa6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_amr(path):\n",
    "    id_dict = {}\n",
    "    amrs, id_list, ids, sents = [],[],[],[]\n",
    "    amr_str = ''\n",
    "    for line in open(path,'r'):\n",
    "        \n",
    "        if '::en_utt' in line or '::annot_utt' in line:\n",
    "            continue\n",
    "        \n",
    "#         if line.startswith('#'):\n",
    "#             if line.startswith('# ::id'):\n",
    "#                 id = line.strip().split()[2]\n",
    "#                 ids.append(id)\n",
    "#                 id_dict[id] = len(ids)-1\n",
    "#                 id_list.append(id)\n",
    "#             if line.startswith('# ::snt'):\n",
    "#                 snt = line[2:].strip().replace('::snt ', '')\n",
    "#                 sents.append(snt)\n",
    "#             continue\n",
    "            \n",
    "\n",
    "            \n",
    "        elif '::id' in line or '::snt' in line:\n",
    "            if line.startswith('::id'):\n",
    "                id = line.strip().split()[1]\n",
    "                ids.append(id)\n",
    "                id_dict[id] = len(ids)-1\n",
    "                id_list.append(id)\n",
    "            if line.startswith('::snt'):\n",
    "                snt = line.strip().replace('::snt ', '')\n",
    "                sents.append(snt)\n",
    "            continue\n",
    "\n",
    "        line = line.strip()\n",
    "        if line == '':\n",
    "            if amr_str != '':\n",
    "                amrs.append(amr_str.strip())\n",
    "                amr_str = ''\n",
    "        else:\n",
    "            amr_str = amr_str + line + ' '\n",
    "\n",
    "    if amr_str != '':\n",
    "        amrs.append(amr_str.strip())\n",
    "        amr_str = ''\n",
    "        \n",
    "    return (amrs, ids, sents), id_list\n",
    "\n",
    "def get_amr_ngrams(path, max_ngrams=3, stat_save_path=None, raw=False, id_list_tmp=list()):\n",
    "    \n",
    "    data, raw_data, sentences = list(), list(), list()\n",
    "\n",
    "    if stat_save_path:\n",
    "        f = open(stat_save_path, 'w')\n",
    "\n",
    "    (lines, amrids, sents), id_list = read_amr(path) \n",
    "    \n",
    "    if len(amrids)==0:\n",
    "        amrids = id_list_tmp\n",
    "        \n",
    "    for line, amrid, snt in zip(lines, amrids, sents):\n",
    "        \n",
    "        if line:\n",
    "            raw_data.append(line)\n",
    "            sentences.append(snt)\n",
    "            try:\n",
    "                amr = AMRGraph(line.strip())\n",
    "            except AssertionError:\n",
    "                assert False\n",
    "            amr.revert_of_edges()\n",
    "            ngrams = amr.extract_ngrams(max_ngrams, multi_roots=True) # dict(list(tuple))\n",
    "            \n",
    "            length = 0\n",
    "            for k, v in ngrams.items():\n",
    "                length+=len(v)\n",
    "            #data.append(NgramInst(ngram=ngrams, length=len(amr.edges)))\n",
    "            data.append(NgramInst(ngram=ngrams, length=length))\n",
    "            if stat_save_path:\n",
    "                print(len(amr), len(ngrams[1]), len(ngrams[2]), len(ngrams[3]), file=f)\n",
    "\n",
    "    if stat_save_path:\n",
    "        f.close()\n",
    "    if raw:\n",
    "        return data, raw_data, sentences, id_list\n",
    "    else:\n",
    "        return data, id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6ac21c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_amr_data(directory, max_ngrams=3):\n",
    "    \n",
    "    train_instances, valid_instances = list(), list()\n",
    "    \n",
    "    fnames = ['amrs-massive-val', 'amrs-massive-train']\n",
    "    \n",
    "    for fname in fnames:\n",
    "        \n",
    "        for pth in directory.glob('**/*'):\n",
    "\n",
    "            if fname in pth.name:\n",
    "                print(pth.name)\n",
    "                \n",
    "                ngramInstances, hypotheses, raw_data, sentences, ids = list(), list(), list(), list(), list()\n",
    "\n",
    "                h, r, s, i = get_amr_ngrams(pth, max_ngrams, raw=True)\n",
    "\n",
    "    #             amr_ngrams_filtered_temp = [item for item in h.ngram[2] if ':ARG' in item[1]]\n",
    "    \n",
    "                if max_ngrams == 1:\n",
    "                    amr_ngrams_filtered = [h[i].ngram[1] for i in range(len(h))]\n",
    "                elif max_ngrams == 2:\n",
    "                    amr_ngrams_filtered = [h[i].ngram[1] + h[i].ngram[2] for i in range(len(h))]\n",
    "                else:\n",
    "                    amr_ngrams_filtered = [h[i].ngram[1] + h[i].ngram[2] + h[i].ngram[3] for i in range(len(h))]\n",
    "                    \n",
    "                ngramInstances.extend(h)\n",
    "\n",
    "                # consider filtering out a few degenerate utts of single tokens\n",
    "                hypotheses.extend(amr_ngrams_filtered)\n",
    "                raw_data.extend(r)\n",
    "                sentences.extend(s)\n",
    "                ids.extend(i)\n",
    "            \n",
    "                for ngramInst, hypo, raw_amr, sent, identifier in zip(ngramInstances, hypotheses, raw_data, sentences, ids):\n",
    "\n",
    "                    if 'en-US' in identifier and len(sent.split())>1:\n",
    "                        \n",
    "                        thisInstance = {'question': sent, 'amr_ngrams': hypo, 'ngramInstance': ngramInst, 'raw_amr': raw_amr, 'id': identifier}\n",
    "\n",
    "                        if 'val' in fname:\n",
    "                            valid_instances.append(thisInstance)\n",
    "                        else:\n",
    "                            train_instances.append(thisInstance)\n",
    "                    \n",
    "    return train_instances, valid_instances\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "30add09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rand_idx(num_samples, train_instances):\n",
    "\n",
    "    rand_idxs = list()\n",
    "    for _ in range(num_samples):\n",
    "        rand_idxs.append(random.randint(0, len(train_instances)))\n",
    "\n",
    "    return list(set(rand_idxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0f8d9783",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompts_list(max_ngrams=3, num_samples=8):\n",
    "    \n",
    "    these_amr_prompts = []\n",
    "    \n",
    "    #train_sample = random.sample(train_instances, 12)\n",
    "    \n",
    "    targets = ['amr_ngrams', 'raw_amr']\n",
    "            \n",
    "    train_instances, valid_instances = get_amr_data(dir_, max_ngrams=max_ngrams)\n",
    "    \n",
    "    rand_idxs = get_rand_idx(num_samples, train_instances)\n",
    "    \n",
    "    train_sample = list()\n",
    "    \n",
    "    for thisIdx in rand_idxs:\n",
    "    \n",
    "        train_sample.append(train_instances[thisIdx])\n",
    "    \n",
    "    for target in targets:\n",
    "     \n",
    "        for idx, thisInstance in enumerate(valid_instances):\n",
    "\n",
    "            if target=='amr_ngrams':\n",
    "                tgt_string = 'List of semantic frames'\n",
    "            else:\n",
    "                tgt_string = 'Abstract Meaning Representation (AMR)'\n",
    "\n",
    "            amr_dialog = [\n",
    "                        {\"role\": \"system\", \"content\": f\"Decompose the utterance into a {tgt_string} like in the examples.\"}\n",
    "                    ]\n",
    "            \n",
    "            for sample in train_sample:\n",
    "                amr_dialog.append({\"role\": \"user\", \"content\": f\"Utterance: {sample['question']}\\n{tgt_string}: \"})\n",
    "                amr_dialog.append({\"role\": \"assistant\", \"content\": f\"{sample[target]}\"})\n",
    "\n",
    "            finalUserTurn = {\"role\": \"user\", \"content\": f\"Utterance: {thisInstance['question']}\\n{tgt_string}: \"}\n",
    "\n",
    "            amr_dialog.append(finalUserTurn)\n",
    "\n",
    "            thisInstance = {\"dialog\": amr_dialog, \n",
    "                            \"question\": thisInstance['question'], \n",
    "                            \"target\": target,\n",
    "                            \"amr_ngrams\": thisInstance['amr_ngrams'],\n",
    "                            \"ngramInstance\": thisInstance['ngramInstance'],\n",
    "                            \"max_ngrams\": max_ngrams,\n",
    "                            \"num_samples_in_prompt\": num_samples,\n",
    "                           \"raw_amr\": thisInstance['raw_amr'],\n",
    "                           \"id\": thisInstance['id']}\n",
    "            these_amr_prompts.append(thisInstance)\n",
    "            \n",
    "    return these_amr_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f58a9dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amrs-massive-val.txt\n",
      "amrs-massive-train.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "massive_prompts_1_8 = get_prompts_list(max_ngrams=1, num_samples=8)\n",
    "\n",
    "len(massive_prompts_1_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5409bcab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dialog': [{'role': 'system',\n",
       "   'content': 'Decompose the utterance into a List of semantic frames like in the examples.'},\n",
       "  {'role': 'user',\n",
       "   'content': \"Utterance: what's two plus two\\nList of semantic frames: \"},\n",
       "  {'role': 'assistant',\n",
       "   'content': \"[('equal-01',), ('sum-of',), ('amr-unknown',), ('2',), ('2',)]\"},\n",
       "  {'role': 'user',\n",
       "   'content': 'Utterance: did angelina jolie leave brad pitt\\nList of semantic frames: '},\n",
       "  {'role': 'assistant',\n",
       "   'content': \"[('leave-15',), ('amr-unknown',), ('person',), ('person',), ('name',), ('name',), ('angelina',), ('jolie',), ('brad',), ('pitt',)]\"},\n",
       "  {'role': 'user',\n",
       "   'content': \"Utterance: what's three plus three hundred and fifty five\\nList of semantic frames: \"},\n",
       "  {'role': 'assistant',\n",
       "   'content': \"[('equal-01',), ('sum-of',), ('amr-unknown',), ('355',), ('3',)]\"},\n",
       "  {'role': 'user',\n",
       "   'content': 'Utterance: how far away is the sun\\nList of semantic frames: '},\n",
       "  {'role': 'assistant',\n",
       "   'content': \"[('far-01',), ('star',), ('amr-unknown',), ('name',), ('sun',)]\"},\n",
       "  {'role': 'user',\n",
       "   'content': 'Utterance: how many miles in five kilometers\\nList of semantic frames: '},\n",
       "  {'role': 'assistant',\n",
       "   'content': \"[('have-quant-91',), ('distance-quantity',), ('distance-quantity',), ('amr-unknown',), ('5',), ('kilometer',), ('mile',)]\"},\n",
       "  {'role': 'user',\n",
       "   'content': 'Utterance: i need the stock price for amazon\\nList of semantic frames: '},\n",
       "  {'role': 'assistant',\n",
       "   'content': \"[('need-01',), ('price-01',), ('thing',), ('i',), ('stock',), ('company',), ('name',), ('amazon',)]\"},\n",
       "  {'role': 'user',\n",
       "   'content': 'Utterance: how to calculate trigonametry\\nList of semantic frames: '},\n",
       "  {'role': 'assistant',\n",
       "   'content': \"[('calculate-01',), ('thing',), ('amr-unknown',), ('mathematics',), ('name',), ('trigonometry',)]\"},\n",
       "  {'role': 'user',\n",
       "   'content': 'Utterance: how many centimeter make one foot\\nList of semantic frames: '},\n",
       "  {'role': 'assistant',\n",
       "   'content': \"[('have-quant-91',), ('distance-quantity',), ('distance-quantity',), ('amr-unknown',), ('1',), ('foot',), ('centimeter',)]\"},\n",
       "  {'role': 'user',\n",
       "   'content': 'Utterance: what are some updates about the stock market\\nList of semantic frames: '}],\n",
       " 'question': 'what are some updates about the stock market',\n",
       " 'target': 'amr_ngrams',\n",
       " 'amr_ngrams': [('update-02',),\n",
       "  ('amr-unknown',),\n",
       "  ('market-01',),\n",
       "  ('some',),\n",
       "  ('stock',)],\n",
       " 'ngramInstance': NgramInst(ngram={1: [('update-02',), ('amr-unknown',), ('market-01',), ('some',), ('stock',)]}, length=5),\n",
       " 'max_ngrams': 1,\n",
       " 'num_samples_in_prompt': 8,\n",
       " 'raw_amr': '(u / update-02 :ARG2 (a / amr-unknown) :topic (m / market-01 :ARG1 (s / stock)) :mod (s2 / some))',\n",
       " 'id': '2997-en-US'}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "massive_prompts_1_8[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "aec5af14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(massive_prompts_1_8[0]['ngramInstance'][0][1])\n",
    "\n",
    "#massive_prompts_1_8[0]['ngramInstance'][0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b6e070fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dialog': [{'role': 'system',\n",
       "   'content': 'Decompose the utterance into a Abstract Meaning Representation (AMR) like in the examples.'},\n",
       "  {'role': 'user',\n",
       "   'content': \"Utterance: what's two plus two\\nAbstract Meaning Representation (AMR): \"},\n",
       "  {'role': 'assistant',\n",
       "   'content': '(e / equal-01 :ARG1 (s / sum-of :op1 2 :op2 2) :ARG2 (a / amr-unknown))'},\n",
       "  {'role': 'user',\n",
       "   'content': 'Utterance: did angelina jolie leave brad pitt\\nAbstract Meaning Representation (AMR): '},\n",
       "  {'role': 'assistant',\n",
       "   'content': '(l / leave-15 :ARG0 (p / person :name (n / name :op1 \"angelina\" :op2 \"jolie\")) :ARG1 (p2 / person :name (n2 / name :op1 \"brad\" :op2 \"pitt\")) :polarity (a / amr-unknown))'},\n",
       "  {'role': 'user',\n",
       "   'content': \"Utterance: what's three plus three hundred and fifty five\\nAbstract Meaning Representation (AMR): \"},\n",
       "  {'role': 'assistant',\n",
       "   'content': '(e / equal-01 :ARG1 (s / sum-of :op1 3 :op2 355) :ARG2 (a / amr-unknown))'},\n",
       "  {'role': 'user',\n",
       "   'content': 'Utterance: how far away is the sun\\nAbstract Meaning Representation (AMR): '},\n",
       "  {'role': 'assistant',\n",
       "   'content': '(f / far-01 :ARG1 (s / star :name (n / name :op1 \"sun\")) :extent (a / amr-unknown))'},\n",
       "  {'role': 'user',\n",
       "   'content': 'Utterance: how many miles in five kilometers\\nAbstract Meaning Representation (AMR): '},\n",
       "  {'role': 'assistant',\n",
       "   'content': '(h / have-quant-91 :ARG1 (d / distance-quantity :unit (m / mile)) :ARG2 (a / amr-unknown) :ARG4 (d2 / distance-quantity :quant 5 :unit (k / kilometer)))'},\n",
       "  {'role': 'user',\n",
       "   'content': 'Utterance: i need the stock price for amazon\\nAbstract Meaning Representation (AMR): '},\n",
       "  {'role': 'assistant',\n",
       "   'content': '(n3 / need-01 :ARG0 (i / i) :ARG1 (t / thing :ARG2-of (p / price-01 :ARG1 (s / stock :mod (c / company :name (n / name :op1 \"amazon\"))))))'},\n",
       "  {'role': 'user',\n",
       "   'content': 'Utterance: how to calculate trigonametry\\nAbstract Meaning Representation (AMR): '},\n",
       "  {'role': 'assistant',\n",
       "   'content': '(c / calculate-01 :ARG1 (t / thing :mod (m / mathematics :name (n / name :op1 \"trigonometry\"))) :manner (a / amr-unknown))'},\n",
       "  {'role': 'user',\n",
       "   'content': 'Utterance: how many centimeter make one foot\\nAbstract Meaning Representation (AMR): '},\n",
       "  {'role': 'assistant',\n",
       "   'content': '(h / have-quant-91 :ARG1 (d / distance-quantity :unit (c / centimeter)) :ARG2 (a / amr-unknown) :ARG4 (d2 / distance-quantity :quant 1 :unit (f / foot)))'},\n",
       "  {'role': 'user',\n",
       "   'content': 'Utterance: how long is the great wall of china\\nAbstract Meaning Representation (AMR): '}],\n",
       " 'question': 'how long is the great wall of china',\n",
       " 'target': 'raw_amr',\n",
       " 'amr_ngrams': [('long-03',),\n",
       "  ('wall',),\n",
       "  ('amr-unknown',),\n",
       "  ('name',),\n",
       "  ('great',),\n",
       "  ('wall',),\n",
       "  ('of',),\n",
       "  ('china',)],\n",
       " 'ngramInstance': NgramInst(ngram={1: [('long-03',), ('wall',), ('amr-unknown',), ('name',), ('great',), ('wall',), ('of',), ('china',)]}, length=8),\n",
       " 'max_ngrams': 1,\n",
       " 'num_samples_in_prompt': 8,\n",
       " 'raw_amr': '(l / long-03 :ARG1 (w / wall :name (n / name :op1 \"great\" :op2 \"wall\" :op3 \"of\" :op4 \"china\")) :ARG2 (a / amr-unknown))',\n",
       " 'id': '14709-en-US'}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "massive_prompts_1_8[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e721fcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_path = Path('../data/llama-massive-prompts_2023-08-07.json')\n",
    "\n",
    "with open(write_path, 'w') as fout:\n",
    "    #data = json.dumps(massive_prompts_1_8)\n",
    "    json.dump(massive_prompts_1_8, fout, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3699bfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "thisHyp = {1: [('share-border-91',), ('border',), ('amr-unknown',), ('country',), ('name',), ('spain',), ('morocco',)]}\n",
    "thisRef = {1: [('border-01',), ('amr-unknown',), ('country',), ('country',), ('name',), ('name',), ('spain',), ('morrocco',)]} \n",
    "\n",
    "cnt_match_ngrams = 0\n",
    "for ngram in thisHyp[1]:\n",
    "    if ngram in thisRef[1]:\n",
    "        cnt_match_ngrams+=1\n",
    "#print(f\"Sembleu: {cnt_match_ngrams/len(thisRef)}\")\n",
    "\n",
    "weights = (1.0,)\n",
    "smoofunc = getattr(SmoothingFunction(), 'method3')\n",
    "\n",
    "thisHyp = NgramInst(ngram=thisHyp, length=1)\n",
    "thisRef = NgramInst(ngram=thisRef, length=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "73f79993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('share-border-91',),\n",
       " ('border',),\n",
       " ('amr-unknown',),\n",
       " ('country',),\n",
       " ('name',),\n",
       " ('spain',),\n",
       " ('morocco',)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thisHyp.ngram[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6280a175",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "33e0203d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6\n"
     ]
    }
   ],
   "source": [
    "def brevity_penalty(closest_ref_len, hyp_len):\n",
    "    if hyp_len > closest_ref_len:\n",
    "        return 1.0\n",
    "    # If hypothesis is empty, brevity penalty = 0 should result in BLEU = 0.0\n",
    "    elif hyp_len == 0:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return math.exp(1 - closest_ref_len / hyp_len)\n",
    "\n",
    "def closest_ref_length_amr(references, hyp_len):\n",
    "    \"\"\"\n",
    "    This function finds the reference that is the closest length to the\n",
    "    hypothesis. The closest reference length is referred to as *r* variable\n",
    "    from the brevity penalty formula in Papineni et. al. (2002)\n",
    "\n",
    "    :param references: A list of reference translations.\n",
    "    :type references: list(list(str))\n",
    "    :param hypothesis: The length of the hypothesis.\n",
    "    :type hypothesis: int\n",
    "    :return: The length of the reference that's closest to the hypothesis.\n",
    "    :rtype: int\n",
    "    \"\"\"\n",
    "    ref_lens = (reference.length for reference in references)\n",
    "    closest_ref_len = min(ref_lens, key=lambda ref_len:\n",
    "                          (abs(ref_len - hyp_len), ref_len))\n",
    "    return closest_ref_len\n",
    "\n",
    "def modified_precision_amr(references, hypothesis, n):\n",
    "    # Extracts all ngrams in hypothesis\n",
    "    # Set an empty Counter if hypothesis is empty.\n",
    "    counts = Counter(hypothesis.ngram[n]) if n in hypothesis.ngram else Counter()\n",
    "    #print 'counts', counts\n",
    "    # Extract a union of references' counts.\n",
    "    ## max_counts = reduce(or_, [Counter(ngrams(ref, n)) for ref in references])\n",
    "    max_counts = {}\n",
    "    for reference in references:\n",
    "        reference_counts = Counter(reference.ngram[n]) if n in reference.ngram else Counter()\n",
    "        for ngram in counts:\n",
    "            max_counts[ngram] = max(max_counts.get(ngram, 0),\n",
    "                                    reference_counts[ngram])\n",
    "    #print('max_counts', max_counts)\n",
    "\n",
    "    # Assigns the intersection between hypothesis and references' counts.\n",
    "    clipped_counts = {ngram: min(count, max_counts[ngram])\n",
    "                      for ngram, count in list(counts.items())}\n",
    "    #print('clipped_counts', clipped_counts)\n",
    "\n",
    "    numerator = sum(clipped_counts.values())\n",
    "    denominator = sum(counts.values())\n",
    "    ## Ensures that denominator is minimum 1 to avoid ZeroDivisionError.\n",
    "    ## Usually this happens when the ngram order is > len(reference).\n",
    "    #denominator = max(1, sum(counts.values()))\n",
    "\n",
    "    if denominator == 0:\n",
    "        return None\n",
    "\n",
    "    return Fraction(numerator, denominator, _normalize=False)\n",
    "\n",
    "\n",
    "def corpus_bleu(list_of_references, hypotheses, weights=(0.34, 0.33, 0.33),\n",
    "                smoothing_function=None, auto_reweigh=False,\n",
    "                emulate_multibleu=False):\n",
    "    # Before proceeding to compute BLEU, perform sanity checks.\n",
    "\n",
    "    p_numerators = Counter() # Key = ngram order, and value = no. of ngram matches.\n",
    "    p_denominators = Counter() # Key = ngram order, and value = no. of ngram in ref.\n",
    "    hyp_lengths, ref_lengths = 0, 0\n",
    "\n",
    "    assert len(list_of_references) == len(hypotheses), \\\n",
    "            \"The number of hypotheses and their reference(s) should be the same\"\n",
    "\n",
    "    # Iterate through each hypothesis and their corresponding references.\n",
    "    for references, hypothesis in zip(list_of_references, hypotheses):\n",
    "        assert type(hypothesis.ngram) == dict and \\\n",
    "                all(type(reference.ngram) == dict for reference in references)\n",
    "        # For each order of ngram, calculate the numerator and\n",
    "        # denominator for the corpus-level modified precision.\n",
    "        for i, _ in enumerate(weights, start=1):\n",
    "            p_i = modified_precision_amr(references, hypothesis, i)\n",
    "            if p_i == None:\n",
    "                continue\n",
    "            p_numerators[i] += p_i.numerator\n",
    "            p_denominators[i] += p_i.denominator\n",
    "\n",
    "        # Calculate the hypothesis length and the closest reference length.\n",
    "        # Adds them to the corpus-level hypothesis and reference counts.\n",
    "        hyp_len =  hypothesis.length\n",
    "        hyp_lengths += hyp_len\n",
    "        ref_lengths += closest_ref_length_amr(references, hyp_len)\n",
    "\n",
    "    # Calculate corpus-level brevity penalty.\n",
    "    bp = brevity_penalty(ref_lengths, hyp_lengths)\n",
    "\n",
    "    # Uniformly re-weighting based on maximum hypothesis lengths if largest\n",
    "    # order of n-grams < 4 and weights is set at default.\n",
    "    if auto_reweigh:\n",
    "        max_gram = max([x for x,y in p_denominators.items() if y > 0])\n",
    "        if max_gram < len(weights):\n",
    "            weights = ( 1.0 / max_gram ,) * max_gram\n",
    "            print('Auto_reweigh, max-gram is', max_gram, 'new weight is', weights)\n",
    "\n",
    "    # Collects the various precision values for the different ngram orders.\n",
    "    p_n = [Fraction(p_numerators[i], p_denominators[i], _normalize=False)\n",
    "           for i, _ in enumerate(weights, start=1)]\n",
    "\n",
    "    # Returns 0 if there's no matching n-grams\n",
    "    # We only need to check for p_numerators[1] == 0, since if there's\n",
    "    # no unigrams, there won't be any higher order ngrams.\n",
    "    if p_numerators[1] == 0:\n",
    "        return 0\n",
    "\n",
    "    # If there's no smoothing, set use method0 from SmoothinFunction class.\n",
    "    if not smoothing_function:\n",
    "        smoothing_function = SmoothingFunction().method0\n",
    "    # Smoothen the modified precision.\n",
    "    # Note: smoothing_function() may convert values into floats;\n",
    "    #       it tries to retain the Fraction object as much as the\n",
    "    #       smoothing method allows.\n",
    "    p_n = smoothing_function(p_n, references=references, hypothesis=hypothesis,\n",
    "                             hyp_len=hyp_len, emulate_multibleu=emulate_multibleu)\n",
    "    s = (w * math.log(p_i) for i, (w, p_i) in enumerate(list(zip(weights, p_n))))\n",
    "    s =  bp * math.exp(math.fsum(s))\n",
    "    return round(s, 4) if emulate_multibleu else s\n",
    "\n",
    "def sentence_bleu(references, hypothesis, weights=(0.34, 0.33, 0.33),\n",
    "                  smoothing_function=None, auto_reweigh=False,\n",
    "                  emulate_multibleu=False):\n",
    "    return corpus_bleu([references], [hypothesis],\n",
    "                        weights, smoothing_function, auto_reweigh,\n",
    "                        emulate_multibleu)\n",
    "\n",
    "\n",
    "sntbleu = round(sentence_bleu([thisRef], thisHyp, weights=weights, smoothing_function=smoofunc, auto_reweigh=False), 1)\n",
    "print(sntbleu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f891e577",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f418477",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf71315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# physics examples\n",
    "\n",
    "dialogs = [\n",
    "        [\n",
    "            {\"role\": \"system\", \"content\": \"Decompose the teacher's instructions into a list of numbered main events. Also decompose each event into its main arguments (ARG) and event modifiers (MOD) that help answer 'Who did what to whom when where and why?' Also provide lists of event relations, main events, and associated social attitudes.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Teacher: So today, you're going to be setting up another pulley in the lab, um, to gather a little more data to, um, solidify your understanding of pulleys. So far you've set up 4 - or you've done some, um, testing with 4 different pulleys set up, okay. Does anyone remember what those names are without looking of the 4 different pulleys set up?\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"\"\"Main events:\\n1. So today, you're going to be setting up another pulley in the lab,\n",
    "Event=(e1, set-up)\n",
    "ARG=(z1, \"you\", actor)\n",
    "ARG=(z2, \"another pulley\", undergoer)\n",
    "MOD=(z3, \"today\", time)\n",
    "MOD=(z4, \"lab\", location)\n",
    "\n",
    "2. to gather a little more data\n",
    "Event=(e2, gather)\n",
    "ARG=(z5, \"you\", actor)\n",
    "ARG=(z6, \"more data\", theme)\n",
    "\n",
    "3. your understanding of pulleys\n",
    "Event=(e3, understand)\n",
    "ARG=(z5, \"you\", experiencer)\n",
    "ARG=(z7, \"pulleys\", stimulus)\n",
    "\n",
    "4. to, um, solidify your understanding of pulleys\n",
    "Event=(e4, solidify)\n",
    "ARG=(z5, \"you\", actor)\n",
    "ARG=(z8, e3, theme)\n",
    "\n",
    "5. So far you've set up 4,\n",
    "Event=(e5, set-up)\n",
    "ARG=(z5, \"you\", actor)\n",
    "ARG=(z9, \"4 pulleys\", undergoer)\n",
    "\n",
    "6. 4 different pulleys set up\n",
    "Event=(e6, set-up)\n",
    "ARG=(z10, \"4 different pulleys set up\", undergoer)\n",
    "\n",
    "7. you've done some, um, testing with 4 different pulleys set up\n",
    "Event=(e7, test)\n",
    "ARG=(z5, \"you\", agent)\n",
    "ARG=(z10, \"4 different pulleys set up\", undergoer)\n",
    "\n",
    "8. names of the 4 different pulleys set up\n",
    "Event=(e8, name)\n",
    "ARG=(z10, \"4 different pulleys set up\", named)\n",
    "\n",
    "9. without looking \n",
    "Event=(e9, look)\n",
    "ARG=(z5, \"you\", experiencer)\n",
    "ARG=(z10, e8, stimulus)\n",
    "POLARITY=(z11, \"-\")\n",
    "\n",
    "10. Does anyone remember what those names are of the 4 different pulleys set up?\n",
    "Event=(e10, remember)\n",
    "ARG=(z12, unknown, experiencer),\n",
    "ARG=(z10, e8, stimulus)\n",
    "MOD=(z13, e9, manner)\n",
    "\n",
    "Relationships:\n",
    "Relation=(e1, have-purpose, e2)\n",
    "Relation=(e1, have-purpose, e4)\n",
    "Relation=(e3, precondition, e1)\n",
    "Relation=(e4, scalar-increase, e3)\n",
    "Relation=(e5, time-before, e1)\n",
    "Relation=(e6, precondition, e7)\n",
    "Relation=(e7, time-before, e1)\n",
    "Relation=(e8, property, z9)\n",
    "Relation=(e10, time-overlap, e9)\n",
    "Relation=(z12, subset-of, z5)\n",
    "\n",
    "Central events: e1, e10\n",
    "e1: plan for today\n",
    "e10: request for information\n",
    "\n",
    "Social attitudes:\n",
    "Mutual belief\n",
    "Shared plans\n",
    "Obligations\"\"\"},\n",
    "            {\"role\": \"user\", \"content\": \"Teacher: Why. Right? It's not what you chose out of 4 multiple choice options, it's why did you choose that. Why does that option make the most sense.\"}\n",
    "        ],\n",
    "        [\n",
    "            {\"role\": \"system\", \"content\": \"Decompose the teacher's instructions into a list of numbered main events. Also decompose each event into its main arguments (ARG) and event modifiers (MOD) that help answer 'Who did what to whom when where and why?' Also provide lists of event relations, main events, and associated social attitudes.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Teacher: So today, you're going to be setting up another pulley in the lab, um, to gather a little more data to, um, solidify your understanding of pulleys. So far you've set up 4 - or you've done some, um, testing with 4 different pulleys set up, okay. Does anyone remember what those names are without looking of the 4 different pulleys set up?\\nMeaning representation:{instances[1][2]}\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"\"\"Main events:\\n1. So today, you're going to be setting up another pulley in the lab,\n",
    "                    Event=(e1, set-up)\n",
    "                    ARG=(z1, \"you\", actor)\n",
    "                    ARG=(z2, \"another pulley\", undergoer)\n",
    "                    MOD=(z3, \"today\", time)\n",
    "                    MOD=(z4, \"lab\", location)\n",
    "\n",
    "                    2. to gather a little more data\n",
    "                    Event=(e2, gather)\n",
    "                    ARG=(z5, \"you\", actor)\n",
    "                    ARG=(z6, \"more data\", theme)\n",
    "\n",
    "                    3. your understanding of pulleys\n",
    "                    Event=(e3, understand)\n",
    "                    ARG=(z5, \"you\", experiencer)\n",
    "                    ARG=(z7, \"pulleys\", stimulus)\n",
    "\n",
    "                    4. to, um, solidify your understanding of pulleys\n",
    "                    Event=(e4, solidify)\n",
    "                    ARG=(z5, \"you\", actor)\n",
    "                    ARG=(z8, e3, theme)\n",
    "\n",
    "                    5. So far you've set up 4,\n",
    "                    Event=(e5, set-up)\n",
    "                    ARG=(z5, \"you\", actor)\n",
    "                    ARG=(z9, \"4 pulleys\", undergoer)\n",
    "\n",
    "                    6. 4 different pulleys set up\n",
    "                    Event=(e6, set-up)\n",
    "                    ARG=(z10, \"4 different pulleys set up\", undergoer)\n",
    "\n",
    "                    7. you've done some, um, testing with 4 different pulleys set up\n",
    "                    Event=(e7, test)\n",
    "                    ARG=(z5, \"you\", agent)\n",
    "                    ARG=(z10, \"4 different pulleys set up\", undergoer)\n",
    "\n",
    "                    8. names of the 4 different pulleys set up\n",
    "                    Event=(e8, name)\n",
    "                    ARG=(z10, \"4 different pulleys set up\", named)\n",
    "\n",
    "                    9. without looking \n",
    "                    Event=(e9, look)\n",
    "                    ARG=(z5, \"you\", experiencer)\n",
    "                    ARG=(z10, e8, stimulus)\n",
    "                    POLARITY=(z11, \"-\")\n",
    "\n",
    "                    10. Does anyone remember what those names are of the 4 different pulleys set up?\n",
    "                    Event=(e10, remember)\n",
    "                    ARG=(z12, unknown, experiencer),\n",
    "                    ARG=(z10, e8, stimulus)\n",
    "                    MOD=(z13, e9, manner)\n",
    "\n",
    "                    Relationships:\n",
    "                    Relation=(e1, have-purpose, e2)\n",
    "                    Relation=(e1, have-purpose, e4)\n",
    "                    Relation=(e3, precondition, e1)\n",
    "                    Relation=(e4, scalar-increase, e3)\n",
    "                    Relation=(e5, time-before, e1)\n",
    "                    Relation=(e6, precondition, e7)\n",
    "                    Relation=(e7, time-before, e1)\n",
    "                    Relation=(e8, property, z9)\n",
    "                    Relation=(e10, time-overlap, e9)\n",
    "                    Relation=(z12, subset-of, z5)\n",
    "\n",
    "                    Central events: e1, e10\n",
    "                    e1: plan for today\n",
    "                    e10: request for information\n",
    "\n",
    "                    Social attitudes:\n",
    "                    Mutual belief\n",
    "                    Shared plans\n",
    "                    Obligations\"\"\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Teacher: Why. Right? It's not what you chose out of 4 multiple choice options, it's why did you choose that. Why does that option make the most sense.\\nMeaning representation: {instances[0][2]}\"}\n",
    "        ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9374a3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dialogs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6528f510",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_path = Path('../data/llama-pulley-prompts.json')\n",
    "\n",
    "\n",
    "if write_path:\n",
    "    with open(write_path, 'w') as fout:\n",
    "        json.dump(dialogs, fout, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb316ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de46d83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bc3f12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
